# ゼロから構築する本格的な数学知識グラフ

## 概要と目標

進化し続ける数学知識のウィキを**知識グラフ**として作成するには、慎重な計画が必要です。その目標は、数学の全分野を**公理、定義、定理、そして例**を相互に接続されたノードとして表現することです。これにより、ユーザー（および機械）は関係性を問い合わせ（例：どの定理が特定の公理に依存しているか）、新たな関連性を発見できるようになります。各知識は、人間が読みやすいドキュメントとして**Quarto**（`.qmd`ファイルとして）で記述されると同時に、機械が読み取り可能なグラフにも供給されます。最終的に、このシステムは**対話的なクエリ**をサポートし、データを**リンクトデータ**として公開し、動的な**可視化**を読者のためにQuartoページに埋め込むことを目指します。これは野心的なスコープであり、本質的には数学のためのセマンティック・ウィキですが、最近のプロジェクトはその実現可能性を示しています。例えば、MaRDIプロジェクトは、定義、公式、研究データを結びつけるために、Wikibaseプラットフォーム（カスタマイズされたWikipedia）上に包括的な数学知識グラフを構築しました。我々のアプローチは、代わりに独自のツールと自動化パイプラインを用いて、グラフをゼロから構築します。

## 知識グラフの設計：ノードと関係性

まず、知識グラフの**スキーマ**、つまりどのような種類のノードとエッジ（関係性）を含むかを定義します。

* **ノードの種類:** 中核となるノードの種類は、 **公理(Axiom)** 、 **定義(Definition)** 、 **定理(Theorem)** （補題、命題、系を含む）、そして **例(Example)** です。各ノードは、その項目を説明するQuartoページに対応します。（任意で、各定理の証明のために **証明(Proof)** ノードを含めることも考えられます。これは依存関係の循環を避けるのに役立ちますが、単純化のために証明は定理ノードに付随するテキストとして扱うこともできます。）
* **属性:** 各ノードは、一意のID、タイトル（例：「定義：群」）、人間が読めるステートメント（Quartoページの内容）、そして場合によっては形式的なステートメント（形式論理や構造化された論理形式でエンコードする場合）などの属性を持ちます。
* **関係性:** 論理的および教育的な関係性を捉えるために、有向エッジを定義します。
  * *「Uses（使用する）」 / 「Depends on（依存する）」:* 定理から、その証明で使われる定義、公理、または以前の定理へのリンク。例えば、ある定理ノードは、それが前提とする概念の定義ノードへのエッジを持つかもしれません。これにより、先行する結果を用いる結果の依存関係グラフが作成されます。
  * *「Defines（定義する）」:* 定義ノードから、それが定義する概念へのリンク（あるいは、概念自体をノードとして扱うこともできますが、概念名でラベル付けされていると考えれば、定義ノードで十分なことが多いです）。
  * *「Has example（例を持つ）」:* 定義や定理から、それを説明する例ノードへのリンク。逆に、例ノードは、それが例示する概念や定理にリンクすることもできます。
  * *「Specializes（特殊化する）」 or 「Generalizes（一般化する）」:* 階層関係を捉えるための任意のリンク（例：ある公理が別の公理の特殊なケースである、またはある定理が別の定理を一般化するなど）。
  * *「Implies（含意する）」:* 多くの定理や公理に内在する論理的な含意（「もし～ならば～」）のための特別な関係。実際、多くの数学的記述は含意と見なすことができます。ある著者が指摘したように、*「定義、公理、定理は、互いに積み重なるif/then文で述べることができる」*のです。定理の内容を仮説と結論の間の論理的含意として表現できますが、グラフのためには完全な論理形式を保存する必要はなく、依存関係のリンクだけで十分な場合が多いです。それでも、「implies」関係の推移的な性質は、これらの関係の連鎖が間接的なつながりの発見を可能にすることを意味します。
* **オントロジーとリンクトデータ:** リンクトデータを実現したいため、これらのノードタイプと関係性をオントロジー（例：RDF/OWLを使用）で形式化すべきです。`math:Axiom`、`math:Theorem`のようなクラスや、`math:uses`、`math:proves`、`math:hasExample`のようなプロパティを定義することができます。既存のオントロジー、例えば**OntoMathPRO**を参考にすることができます。OntoMathPROは、概念や定理などのためのセマンティックスキーマを提供する数学知識のオントロジーであり、Web of Dataへの統合を目指しています。このようなオントロジーを採用またはマッピングすることで、我々のグラフはより相互運用性が高まります。しかし、最初はカスタムスキーマでシンプルに始め、各項目が安定したURI（リンクトデータのため）を持つようにすることもできます。
* **粒度 – 定理 vs. 証明:** 証明をどう扱うかを考えます。一つのアプローチ（依存関係グラフに関するいくつかの議論で使われる）は、各**証明(Proof)**を、それ自体が特定の先行結果を*使用し*、定理を*生み出す*ノードとして扱うことです。これにより、定理Aと定理Bが互いを仮定して証明できる場合に生じる有向サイクルを回避できます（証明が中間ノードを形成します）。証明ノードを実装するのはより複雑なので、最初はこれを省略し、選択された展開順序に基づいて定理の依存関係がDAG（有向非巡回グラフ）を形成すると仮定するかもしれません。ただし、このようなエッジケースには注意が必要です。

グラフスキーマを事前に設計することで、新しいコンテンツが追加される際に、それが知識グラフに一貫して適合することを保証します。すべてのQuartoページは、これらのタイプのいずれかのノードを効果的にインスタンス化し、あるページから別のページを参照するたびに、グラフ内にエッジを定義することになります。

## Quartoによるコンテンツ作成

Quartoは、**コンテンツ作成のフロントエンド**、つまり、公理、定義、定理、例をきれいにフォーマットされたMarkdownで記述する「ウィキ」として機能します。コンテンツを体系的に整理することは、グラフ構築を容易にする上で効果的です。

* **ファイル構成:** 各概念やステートメントに独自のファイル（ノード）を与えるのが賢明です。例えば、`axioms/`, `definitions/`, `theorems/`, `examples/`のようなフォルダ構造にするか、数学のトピック（代数学、解析学など）ごとにサブフォルダで整理することができます。一貫したファイル命名規則（または各ファイルのメタデータ内のID）は、各ノードが一意に識別可能であることを保証するのに役立ちます。
* **Quartoの相互参照機能の使用:** Quartoは、内部リンクや定理のような環境に対する相互参照をサポートしています。各`.qmd`ファイルはタイトルを持ち、他のファイルにリンクできます。実際には、*「各概念が独自のファイルを持ち」*、ノートは互いにハイパーリンクで結ばれます。例えば、群を定義する`group.qmd`と、群の例を含む`example_group.qmd`がある場合、定義ページに例へのリンクを、その逆に例ページに定義へのリンクを設置します。QuartoはこれらをHTML出力でハイパーリンクとしてレンダリングします。参照される他の概念に一貫してリンクすることで、本質的にテキスト内でグラフのエッジを構築していることになります。Quartoの相互参照構文（定理や定義などに`@label`を使用）は、番号付きのラベルとハイパーリンクを自動生成することもできます。例えば、ターゲットに識別子`{#def-group}`があれば、`@def-group`のように書くことで、他の場所にある群の定義を参照できます。この機能を活用することで、リンクが明示的になり、後で解析しやすくなります。
* **YAMLでのメタデータ:** 各QuartoファイルのYAMLフロントマターに、ノードに関するメタデータを含めることができます。例えば：

    ```yaml
    title: "Definition: Group"  
    type: "Definition"  
    id: "def-group"  
    requires: ["axiom-choice", "def-set"]  # 任意: 前提条件のIDリスト
    ```

    これは仮の例ですが、`type`や`id`フィールドを追加することは、自動化スクリプトの助けになります。Quartoは使用しないカスタムフィールドを無視しますが、Pythonスクリプトはそれらを読み取ることができます。`requires`フィールド（または同様のもの）は、依存関係をリストするために手動で維持することもできますが、理想的にはほとんどの関係はコンテンツのリンクから収集されます。それでも、メタデータは簡単に解析できない事柄に対して役立ちます。
* **記述スタイル:** ある概念や結果に言及する際は、必ずそれを参照（リンクするか、少なくとも一貫した名前を使用）するようにし、グラフがそれを拾えるようにします。例えば、定理の証明で「... **補題 @lem-somelemma** を用いると、...」と書くことは、読者に情報を与えると同時に、パーサーが掴む何か（リンク`@lem-somelemma`は後に関係「この定理はあの補題を使用する」として抽出できる）を提供します。参照が純粋にテキストである場合、リンクを推測するにはNLPステップ（あるいはLLM）が必要になるかもしれませんが、これを確実に自動化するのはより困難です。したがって、このウィキの執筆規約の一部は、*「使用する概念や結果のページには常にリンクする」*べきです。こうすることで、知識グラフは本質的に手動で、ただテキストで表現されているだけ、という形で織りなされていきます。

要約すると、Quartoは数学コンテンツのための共同編集環境となります。各Quartoノードは、（LaTeXの数式などを用いて）人間が読みやすい方法で書かれ、同時にバックエンドがグラフを構築するために必要なフック（リンク、ID、メタデータ）も持ち合わせます。

## バックエンドのグラフ構築（PythonとLeanの統合）

コンテンツが揃ったら、**グラフ構造を抽出し**、クエリ可能な形式で保存する必要があります。Pythonはこのバックエンドのデータ処理に最適な選択肢です。また、可能な限り形式化と検証のために**Lean4**を統合することもできます。

**1. Quarto出力の解析:** 一つのアプローチは、Quartoサイトの*レンダリングされたHTML*を解析して、リンクや構造化データを抽出することです。Quartoは各`.qmd`に対してHTMLページを生成します。Pythonライブラリの**BeautifulSoup**を使ってこれらのページを解析するのは効果的です。これは、あるプロジェクトがLeanのHTMLドキュメントを解析した方法と似ています。そのプロジェクトでは、Leanの数学ライブラリをコンパイルしてドキュメント生成ツールを使用し、その後*「mathlib4のドキュメントにはすべての数学的オブジェクトが含まれており... 名前、階層関係、説明などの情報を抽出するために、PythonライブラリのBeautifulSoupがHTMLを解析し、JSONに変換するために使用される」*とあります。我々も同じことができます。各HTMLページ（ノード）について、そのタイトル、タイプ、およびそこに含まれる他のページへのすべてのハイパーリンクを収集します。ページAからページBへの各ハイパーリンクは（もしそれが我々のウィキ内の別の数学項目を指していれば）、グラフ内の関係性になります。その関係性のタイプは、文脈やノードのタイプから推測できるかもしれません（例：Aが定理で、それが定義であるBにリンクしている場合、それはAが証明やステートメントでBを*使用する*ことを意味する可能性が高いです）。

* あるいは、生の`.qmd` Markdownファイルを直接解析することもできます。Markdownはリンクの解析が（正規表現やMarkdown ASTを使えば）いくらか簡単です。しかし、Quartoの相互参照構文（`@label`）は、Quartoにレンダリングさせないと解決が難しいかもしれません。妥協案として、Quartoの組み込みサイトJSONや、利用可能であれば他のエクスポート機能を使用します。（Quartoには相互参照のリストやサイトマップを出力するオプションがあるかもしれませんが、なければHTMLの解析で問題ありません。）
* `requires: [...]`のようなYAMLメタデータを活用した場合、YAMLパーサー（例：PyYAML）でフロントマターを解析して、宣言されたエッジを直接取得することもできます。これはテキスト内で見つかったリンクを補完することができます。

**2. グラフデータ構造の構築:** 解析しながら、グラフを構築します。インメモリ構造（PythonのNetworkXなど）を使用することも、データベース用に直接構築することもできます。リンクトデータのためには、**RDFトリプル**を構築することを好むかもしれません。Pythonの**rdflib**ライブラリを使えば、トリプルを簡単に定義し、TurtleやJSON-LDにシリアライズできます。例えば、`定理T`が`定義D`を使用する場合、`(math:T, math:uses, math:D)`というトリプルを追加できます。各ノードも、そのタイプを表明するトリプル、例えば`math:T rdf:type math:Theorem`を持つことになります。各ノードに一意のIDやURI（ページ名やGUIDに基づくことができる）があれば、それらを主語/目的語の識別子として使用します。最終的に、抽出されたすべての関係性を表すトリプルのコレクションが得られます。

プロパティグラフを好む場合や、複雑なクエリが必要な場合は、**Neo4j**のようなグラフデータベースを使用する選択肢もあります。Leanのmathlibの例では、JSONを解析した後、*「知識グラフを構築するためにPythonが採用され、最終的にNeo4jグラフデータベースに保存される」*とあります。同様のことが可能です。Neo4jのPythonドライバ（またはpy2neo）を使ってノードと関係性をアップロードします。Neo4jではCypherクエリで問い合わせができます。しかし、リンクトデータの公開が目標であるため、RDFトリプルストアの方がNeo4jよりも標準的なリンクトデータの実践に沿っているかもしれません。（Neo4jにはRDFプラグインがありますが、純粋なRDF環境に固執する方が公開を単純化できる可能性があります。）

**3. Lean4の統合（任意だが強力）:** Lean4は2つの方法で役割を果たすことができます。

* *形式的な知識源:* Leanの`mathlib`には、何千もの形式的に検証された定義と定理が含まれています。ウィキの記述が正しいことを保証するために、Leanからコンテンツをインポートまたはミラーリングすることができます。例えば、ウィキに定理や公理を追加する際に、それぞれに対してLeanコードを書くことができます。これは多くの作業を伴いますが、高度な厳密性を保証します。Leanはデータを出力することもできます。LeanのAPIやdoc-genのようなツールを使えば、形式的なステートメントの依存関係グラフを抽出できます（Leanはどの補題が証明で使われたかなどを知っています）。そのデータを我々のグラフに組み込むことで、非常に正確なものになります（すべての「uses」エッジが形式的な証明によって保証されます）。欠点は、すべてが形式化されているわけではなく、形式化には時間がかかることです。妥協案として、重要な部分を徐々に形式化するか、公理の内部的な一貫性を検証するためにLeanを使用することが考えられます。
* *クエリと証明支援:* Leanとの統合により、LeanやLeanに接続されたAIエージェントに証明経路を見つけさせることさえ可能になります。例えば、LLMがグラフを探索して関連する補題を見つけ、その後Leanの証明スクリプトを生成しようと試みることができます。実際、ごく最近の研究では、ProofWikiサイトから*「60,000以上のノードと300,000以上のエッジを持つ知識グラフを構築し」*、それをLeanとLLMと統合して証明生成を自動化しました。これは、知識グラフと証明支援系を組み合わせることが最先端のアプローチであることを示しています。我々の文脈では、最初はそこまで進まないかもしれませんが、Leanを念頭に置くことは、後で形式的な証明チェッカーに供給できるような方法でデータを構造化することを意味します。

**4. データの一貫性の確保:** 抽出スクリプトは、コンテンツが変更されるたびに実行されるべきです（CI/CDによる自動化については後述します）。これらは一貫性チェックも実行できます。例えば、定理内のリンクが公理/定義/定理として分類されていないものを指していないか（壊れたリンクや欠落したノードの可能性）、フラグを立てることができます。また、依存関係グラフ内のサイクルやその他の異常を検出することもでき、これはコンテンツの整理方法に論理的な問題があることを示している可能性があります。

このバックエンドプロセスの終わりには、**データが投入された知識グラフ**のデータセットが出来上がります。例えば、すべてのノードとトリプルを含むRDFファイル（TurtleまたはJSON-LD）や、ロードされたデータベースがあるかもしれません。この段階で、我々は本質的に、数学ウィキの機械可読な「頭脳」を手に入れたことになります。

## グラフをリンクトデータとして公開・クエリする

知識グラフを役立てるためには、それを**リンクトデータとして公開**し、対話的にクエリする方法を提供しなければなりません。

* **リンクトデータの公開:** リンクトデータとは、グラフ内の各エンティティが解決可能な**URI**を持つべきだということです。簡単な方法の一つは、QuartoページのURLを識別子として使用することです。例えば、サイトが`mathwiki.org`であれば、群の定義は`https://mathwiki.org/definitions/group`に存在し、それがその概念のURIとして機能します。サイト上でグラフ全体のRDFシリアライゼーション（`.ttl`ファイルなど）を公開することができます（例えば`/graph/mathwiki.ttl`のようなURLで）。理想的には、誰かがページのURIを（HTTPヘッダー経由で）RDFを要求して取得した場合に、そのノードに関する機械可読なデータを得られるように、コンテンツネゴシエーションを設定します。これは、HTMLにRDFデータを埋め込む（`<script type="application/ld+json">` JSON-LDブロックを使用）か、小さなAPIを設定することで実現できます。手っ取り早い解決策は、RDF形式のデータセットのダウンロードリンクと、可能であればクエリ用のSPARQLエンドポイントを提供することです。
* **トリプルストア / SPARQLエンドポイント:** ライブクエリを可能にするために、Apache Jena Fuseki、GraphDB、またはRDF4Jサーバーのような**トリプルストア**をデプロイすることができます。これらにRDFトリプルを供給すると、URL上でSPARQLクエリエンドポイントをホストします。例えば、「定義Xに依存するすべての定理を見つける」というクエリは、`?theorem math:uses math:DefinitionX`というパターンにマッチさせることで答えられます。SPARQLエンドポイントを公開することで、ユーザー（または他のサービス）がデータに対してカスタムクエリを実行できるようになります。これは対話的なクエリという目標に対応します。小さなウェブフォームを構築したり、既存のSPARQL UIを使用してユーザーが質問を入力できるようにしたりできます。さらに、SPARQLの結果（JSONやCSV形式が可能）をスクリプトで取得して、動的なコンテンツ（KGにクエリを投げて特定の概念のすべての例をリストするQuartoページなど）を生成することもできます。
* **グラフクエリAPI:** エンドユーザーにとってSPARQLが難解すぎると感じる場合は、よりシンプルなクエリAPIを実装することもできます。例えば、Pythonバックエンド（Flask/FastAPI）やNode/TypeScriptバックエンドが、一般的なクエリのためのRESTエンドポイント（例：`/uses?theorem=TheoremName`というエンドポイントがその定理が使用するすべてのノードを返す）を公開できます。内部では、それはSPARQLクエリに変換されるか、Neo4jでのルックアップになります。もう一つの現代的なアプローチは、より開発者フレンドリーなクエリインターフェースを提供するために**GraphQL**を使用することです。オントロジー（クラスと関係性）からGraphQLスキーマを自動生成することができます。
* **対話的なクエリインターフェース:** 対話的な探索のためのUIを構築することを考えます。これは、既存のグラフブラウザ（多くのトリプルストアにはウェブインターフェースがあります）を使用するほどシンプルなものから、誰かが概念を入力すると関連項目のグラフが表示される検索バーを構築するほどカスタムなものまであり得ます。TypeScriptにオープンであるなら、ウェブアプリ（おそらくiframe経由でQuartoサイトに埋め込むか、静的なSPAとして）を作成し、対話的なナビゲーションを可能にすることができます。例えば、定理ノードをクリックすると、それが使用する定義やそれに依存する定理が表示されるように展開できます。**D3.js**、**Vis.js**、**Cytoscape.js**のようなライブラリは、ウェブページで対話的なグラフビジュアルをレンダリングするのに役立ちます。

真のリンクトオープンデータとして公開することは、再利用を奨励することも意味します。他の人があなたのURIをデリファレンスしてデータを取得できるようになります。（基本的なメタデータにはDublin Coreのような）共通の語彙に合わせたり、該当する場合は外部の数学データベースへのリンクを共有したりすることで、相互運用性が向上します。しかし、主な焦点は、*あなた自身が*自分のニーズに合わせてグラフにクエリできることです。例えば、特定の公理がトポロジーのどの定理でも使用されているかを確認したい場合、ノートをくまなく探すのではなく、数秒でクエリを投げることができます。

## Quartoへのグラフの可視化と埋め込み

ウィキをより洞察に富んだものにするために、知識グラフの一部を**可視化してQuartoページに埋め込みたい**と考えています。これは、読者が特定の項目の文脈（それが何に依存し、何がそれに依存しているか）を理解するのに役立ちます。

これにはいくつかの方法があります。

* **静的な図（MermaidまたはGraphviz）:** 手早く可視化するには、テキストベースのグラフ記述を使用できます。Quartoは、Markdownフェンス内に**Mermaid**図を埋め込むことをサポートしています。例えば、ノードの近傍のMermaid *フローチャート*や*グラフ*記述を生成できます。次のようなMermaidコードブロックは：

    ````
    ```{mermaid}
    graph LR;
      A[Definition X] --> B(Theorem Y);
      A --> C(Theorem Z);
      C --> D[Example Q];
    ```  
    ````

    小さな有向グラフをレンダリングします。Pythonスクリプトでこれらのスニペットを自動生成し、Quartoページに含めることができます（おそらくQuartoフィルターを介して、またはレンダリング中に挿入することで）。Mermaidはかなり柔軟で、Quartoはそれを正しくレンダリングできます（以前のQuartoバージョンにはHTMLエスケープの問題がありましたが、v1.4以降では解決されています）。
* **動的なグラフ可視化:** より豊かな体験のためには、対話的なグラフが理想的です。Quartoで直接**D3.js**などを使用するのは難しいかもしれませんが、カスタムHTML/JSを埋め込むことはできます。一つのアプローチは、データ（おそらくJSON形式）を取得してグラフ（力指向レイアウト、ズーム/パンなど）をレンダリングする小さなHTML + JavaScriptウィジェットを作成することです。これを`<iframe>`や生のHTMLチャンクを使ってQuartoページに埋め込むことができます。別のアプローチは、Pythonを使って対話的なプロットを生成することです。**Plotly**や**Bokeh**のようなライブラリは、ネットワークグラフを扱えるかもしれません。例えば、**pyvis**（vis.jsへのPythonインターフェース）は、対話的なネットワークグラフを生成し、HTMLスニペットとして保存できます。（埋め込みJupyter出力をサポートする）Quartoドキュメント内で、pyvisを使用して現在のトピックのグラフを表示するコードセルを持つことができます。結果はページ内の対話的なフレームとなり、ノードをクリックしたりホバーしたりできます。
* **文脈に応じたグラフの埋め込み:** おそらく、グラフ全体（「数学のすべて」にとっては巨大になるでしょう）を一度に表示するのではなく、グラフの*局所的な近傍*を表示したいでしょう。例えば、定義ページでは、その定義とそれを使用する定理/補題、さらに関連する定義や例のグラフを表示します。定理ページでは、それがどの定義/公理を使用し、どの定理がその上に構築されているかを表示します。これらのサブグラフは、KGへのクエリを介して取得できます。例えば、「定理Y」のページをレンダリングする際に、1ホップ離れたすべてのノード（依存関係グラフにおける先行ノードと後続ノード）を取得するクエリを実行できます。ライブクエリ（SPARQLやAPI経由）を使用する場合は、クライアント側でJSONを取得できます。あるいは、各ノードについてこれらを事前に計算して保存し（ページのYAMLやデータファイル内など）、埋め込みがライブコールを必要としないようにすることもできます。
* **可視化のためのTypeScriptの使用:** TypeScriptに慣れているなら、可視化コンポーネントをTSで開発し、おそらくスタンドアロンのウェブページまたは各ページに埋め込まれた小さなアプリとして開発することができます。TypeScriptはリンクトデータエンドポイントからデータ（例えば、HTTP経由でSPARQLクエリを使用して）を取得し、D3やThree.jsを使用してレンダリングできます。Quartoは外部スクリプトを含めることができるので、これをうまく統合できます。もう一つのアイデアは、サイト上に**Neo4j Browserのような体験**を作成することですが、カスタマイズされたものです。Neo4jのフロントエンドはJSで構築されており、数学知識を探索するユーザーのためにその感覚の一部を再現できるかもしれません。
* **可視化グラフの例:** Lean4 mathlib知識グラフプロジェクトでは、グラフの一部を可視化しました（おそらくNeo4jのツールやGephiで）。それはオフラインでしたが、我々のウィキではページ上の可視化を目指します。概念実証として静的な画像やMermaidでシンプルに始め、データが流れるようになったら徐々に対話的なビジュアルに強化していきます。

可視化を埋め込むことで、読者のためにQuartoウィキを豊かにします。定理を読むだけでなく、それがより大きな全体像にどのように適合するか（どの公理を前提とし、どの後の結果がそれを参照しているかなど）を*見る*ことができます。これは非常に教育的であり、また著者が何かが孤立しているか、多くのものに過度に依存しているかを発見するのにも役立ちます。

## LLMとCI/CDパイプラインによる自動化

この規模のプロジェクト（*数学のすべて*をカバーするのは長期的なミッションです！）を管理するためには、可能な限り多くを自動化する必要があります。**大規模言語モデル（LLM）**と**CI/CDパイプライン**の両方が不可欠になります。

* **LLMによる支援:** 大規模言語モデルは、複数の段階で支援できます。
  * *コンテンツ生成:* LLMを使用して、定義や定理のページを下書きすることができます。例えば、トピックや形式的なステートメントを与えると、LLMは最初の説明や証明の草稿を生成し、それをあなたが検証・編集します。これにより、ウィキの充填が速まる可能性があります。ただし、注意が必要です。LLMは幻覚（ハルシネーション）を起こしたり、微妙な数学的誤りを犯したりする可能性があるため、重要なものについては人間のレビューや（Leanによる）形式的な検証が重要です。
  * *関係抽出:* LLMは、自然言語の証明を読んで、どの先行結果が使用されているかを特定できます。テキストのリンクが不完全な場合、LLMはリンクを推測するのに役立つかもしれません（「この証明はコンパクト性の概念を援用しているようです。その定義にリンクするようにしてください」）。これは、プロンプトベースの分析やファインチューニングで可能になるかもしれません。まさにこの方向で進行中の研究があります – 非形式的な数学テキストを解析し、知識グラフを構築する。例えば、あるフレームワークはProofWikiのエントリをLLMで解析してグラフを構築し、それを証明生成に使用します。同様に、グラフを最新の状態に保つためにLLMを活用できます。新しい定理を書いた後、LLMに（API経由で）参照されているすべての定義や定理をリストアップさせ、それを明示的なリンクと比較して欠けているエッジを捕捉します。
  * *ユーザーへのクエリ応答（QA）:* 直接的なグラフクエリに加えて、知識グラフをコンテキストとして使用するチャットボットとしてLLMをデプロイすることもできます。LLMはユーザーの質問を受け取り、それをグラフクエリ（または検索）に変換し、ウィキへの引用付きで回答を定式化します。これは、常にウィキグラフで関連情報をチェックする数学Q&Aアシスタントのようなものになります（一部のシステムがWikipedia + LLMを使用して質問に答える方法に似ています）。
  * *証明のヒントと自動化:* 依存関係のグラフが与えられれば、LLMは新しい予想を証明するのに役立つ補題を提案するかもしれません。Leanで予想を形式化すれば、LLMはグラフの接続をヒントとして使用してLeanの証明探索を導くことができます。
* **CI/CDパイプライン:** 継続的インテグレーションとデプロイメントを設定することで、システムがスムーズに稼働し続けます。
  * すべてのQuartoコンテンツ、そしておそらくデータスクリプトのために、Gitリポジトリ（例：GitHub/GitLab上）を使用します。あなたや協力者が変更（新しいノードや編集）をプッシュするたびに、CIパイプラインがトリガーされます。
  * **ビルドとテスト:** パイプラインはQuartoを実行してサイトをレンダリングし（マークダウンにエラーがないことを確認）、その後Pythonスクリプトを実行して知識グラフデータを更新します。ここにテストを含めることができます。例えば、Quarto内のすべての`@links`が実際に既存のターゲットに解決されること、重複したIDがないことなどを保証します。テストが失敗した場合、CIはそれを報告し、デプロイ前に問題を修正できるようにします。
  * **Leanによる検証（使用する場合）:** 形式的なステートメントのために並行してLeanプロジェクトを維持している場合、CIは`leanpkg`/`lake build`を実行してすべてのLeanファイルを型チェックすることもできます。証明が壊れた場合（例：ウィキで定理のステートメントを変更したが、Leanの証明を更新していない場合）、CIがそれを捕捉します。
  * **デプロイ:** 成功すると、パイプラインは更新されたQuartoサイトをデプロイできます（例：GitHub Pagesや他の静的ホスティングに公開）。また、更新された知識グラフデータもデプロイできます。例えば、トリプルのTurtleファイルを公開したり、実行中のトリプルストアのデータベースを更新したりできます。一部のトリプルストアはREST更新を許可します。そうでなければ、新しいデータを含むDockerコンテナを再デプロイするかもしれません。別のアプローチは**Wikidata/Wikibase**を使用することです。もし選択するなら、Wikibaseインスタンスにデータをプッシュすることもできます（MaRDIプロジェクトは数百万のアイテムを持つ独自のWikibaseを持っていましたが、既存のソフトウェアを活用するためにゼロから構築しないことを選択しました – 我々のケースではカスタムアプローチで進めます）。
  * **CIにおけるLLMによる継続的改善:** 制御された方法でCIパイプラインにLLMを統合することができます。例えば、夜間に、スタブ記事や欠けている例を見つけるジョブを実行し、LLMに候補テキストを生成させ、それを人間のレビューのために投稿します。あるいは、LLMを使って矛盾をスキャンします（例えば、「定理Xは、述べられているように、リンクされていない概念Yに論理的に依存していますか？」のような質問をすることで）。
  * **バージョニングと進化:** 時間の経過とともに、知識グラフは進化します。gitを使用することは、すべての変更が追跡されることを意味します。データセットのリリースにタグを付けることを検討するかもしれません（特に他の人がリンクトデータを使用する場合、彼らはバージョンを引用するかもしれません）。CIは変更の要約（例：「この更新で定理を5つ追加、定義を2つ更新、壊れたリンクを1つ修正」）を生成し、それを公開してユーザーに知らせることができます。
* **スケーラビリティとメンテナンス:** CI/CDで自動化することで、ノード数が大きくなっても、システムは手動介入なしでサイトとグラフを再生成できます。パフォーマンスが問題になった場合（例えば、数万のノードがあるとグラフ全体を再構築するスクリプトが遅くなる場合）、差分更新を行うことで最適化できます（例：変更されたファイルのみを再処理し、そのエッジを更新する）。堅牢なアプローチは、グラフをデータベースに保存し、毎回ゼロから再構築するのではなく、影響を受ける部分だけを更新することかもしれません。CIは、完全な再構築（おそらく大きな変更のため）と、小さな編集のための迅速な差分更新の両方を処理できます。

要約すると、この知識ベースを管理するためには**自動化が鍵**となります。LLMは手作業を減らすためのインテリジェントなアシスタントとして機能し（ただし監督は必要です）、CI/CDはすべてのコンポーネント – Quartoコンテンツ、知識グラフ抽出、データ提供、サイトデプロイメント – を一つのシームレスなワークフローに統合する接着剤となります。

## 全体のまとめ

ゼロから数学知識グラフウィキを設計するのは大規模な事業ですが、体系的なアプローチをとれば管理可能になります。以下に計画の概要を示します。

1. **スキーマの設計:** どのようなノードと関係性のタイプを持つか（公理、定義、定理、例など、関係性として「uses」「implies」「hasExample」など）を定義します。リンクトデータの互換性のために、既存のオントロジーの採用を検討します。
2. **Quartoでのコンテンツ作成:** 数学コンテンツを`.qmd`ファイルに、1ファイル1ノードで記述します。明確な構造を使用し、言及された他のノードへのハイパーリンク参照を使用します。識別やカスタムフィールド（タイプや前提条件など）のために必要に応じてメタデータ（YAML）を追加します。定理や証明などの一貫したフォーマットのためにQuartoの機能を活用します。
3. **グラフの解析と構築:** Pythonスクリプトを使用してQuartoファイルまたはそのレンダリングされたHTMLを解析し、ノードとその接続を抽出します。知識グラフをRDFトリプル（rdflibを使用）またはグラフデータベースで構築します。各ノードが一意のURIを取得し、タイプ情報とテキスト記述が付加されるようにします。グラフデータ（例：Turtleファイルとして、またはデータベースに）を保存します。
4. **リンクトデータの公開:** グラフのRDFデータをウェブ上でホストします（これは単純なファイルでも、トリプルストア内のSPARQLエンドポイントでも構いません）。誰でも（またはどのプログラムでも）用語のURIをルックアップしてその情報を取得できるようにし、リンクトデータの原則を満たします。高度なクエリのためにSPARQLエンドポイントを設定し、および/または便宜のためにREST/GraphQL APIを提供します。
5. **クエリ結果と可視化の埋め込み:** グラフからデータを引き出すことでQuartoページを強化します。これは、定理ページの上部にグラフにクエリを投げることで自動的に「前提条件：定義X、定理Y」をリストすることを意味するかもしれません。また、各ノードの周りの知識グラフの局所的な部分を可視化するためにグラフ（静的な図にはMermaid、動的なものには対話的なJSを使用）を埋め込みます。これはユーザーが文脈をナビゲートし理解するのに役立ちます。
6. **CI/CDによる自動化:** 継続的インテグレーションパイプラインを使用してすべてを統合します。コンテンツが追加または変更されるたびに、パイプラインはサイトのビルドとグラフの抽出を実行します。また、完全性を維持するためにあらゆる検証（テスト、場合によってはLeanの証明）も実行する必要があります。成功すると、更新されたサイトをデプロイし、リンクトデータのバックエンドを更新します。このプロセスは再現可能で、ほとんど自動であるべきです。
7. **LLMと将来の統合:** コンテンツとメンテナンスを支援するためにLLMを徐々に統合します – 例えば、下書きコンテンツの生成、欠落リンクのチェック、あるいは知識グラフを情報源として使用して自然言語でユーザーと対話するなど。重要な部分で最高の信頼性を確保するために、Lean4のような形式的ツールとの統合を続けます（Leanは、形式的なシステムでの証明を要求することで、偽の定理が導入されないことを保証できます）。

この計画に従うことで、豊かで**自己更新する数学知識ウィキ**を開発できます。これにより、数学の対話的な探索が可能になります。コンセプトのすべての使用例、プロパティのすべての例、定理の依存関係ツリーなどを（SPARQLやカスタムインターフェースを介して）クエリできます。数学者や学生は結果の全体像を見ることから恩恵を受け、自動化ツール（LLM、定理証明器）は構造化されたデータを活用して自動推論のフロンティアを押し進めることができます。このシステムは時間とともに進化します – おそらくより狭い領域から始まり、徐々に拡大していきますが、Quarto + Python + リンクトデータ + 自動化のフレームワークがその成長をサポートします。細心の後援と賢い自動化により、あなたは*「検索可能な数学的結果のデータベース」*と、真に数学のすべてをカバーする対話的な知識グラフをキュレートする軌道に乗るでしょう。

**参考文献:** 上記で詳述したアプローチは、数学的知識管理における既存の研究とツールに基づいています。主なインスピレーションには、数学知識のグラフ構造化のためのif/then論理の使用、Quartoベースのウィキの実践、Leanのmathlibグラフ抽出のようなプロジェクト、数学的知識を表現するためのOntoMathPROオントロジー、MaRDI知識グラフイニシアチブ、そして知識グラフをLLMや形式的証明と組み合わせて数学を自動化する最近の取り組みが含まれます。これらのリソースは、包括的で接続された数学知識のリポジトリを構築するための実現可能性とベストプラクティスを示しています。
