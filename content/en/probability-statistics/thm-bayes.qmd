---
id: thm-bayes
requires:
- def-conditional-probability
- def-event
status: complete
title: Bayes' Theorem
translations:
  en: ../en/probability-statistics/thm-bayes.html
  ja: ../ja/probability-statistics/thm-bayes.html
type: Theorem
---

**Bayes' Theorem** provides a way to calculate [Conditional Probability](def-conditional-probability.qmd) in the "reverse" direction. It relates $P(A|B)$ to $P(B|A)$, allowing us to update beliefs based on new evidence.

## Statement

For [Events](def-event.qmd) $A$ and $B$ with $P(A) > 0$ and $P(B) > 0$:

$$P(A|B) = \frac{P(B|A) \cdot P(A)}{P(B)}$$

## Alternative Forms

### Using Law of Total Probability

If $\{A_1, A_2, ..., A_n\}$ form a partition of the sample space:

$$P(A_i|B) = \frac{P(B|A_i) \cdot P(A_i)}{\sum_{j=1}^n P(B|A_j) \cdot P(A_j)}$$

### Binary Case

For event $A$ and its complement $A^c$:

$$P(A|B) = \frac{P(B|A) \cdot P(A)}{P(B|A) \cdot P(A) + P(B|A^c) \cdot P(A^c)}$$

## Proof

From the definition of conditional probability:
1. $P(A|B) = \frac{P(A \cap B)}{P(B)}$
2. $P(B|A) = \frac{P(A \cap B)}{P(A)}$

From (2): $P(A \cap B) = P(B|A) \cdot P(A)$

Substituting into (1):
$$P(A|B) = \frac{P(B|A) \cdot P(A)}{P(B)}$$

## Terminology

- $P(A)$: **Prior probability** of $A$
- $P(A|B)$: **Posterior probability** of $A$ given evidence $B$
- $P(B|A)$: **Likelihood** of observing $B$ given $A$
- $P(B)$: **Marginal probability** or normalizing constant

## Applications

### Medical Diagnosis
- $A$: Patient has disease
- $B$: Test is positive
- Calculate $P(\text{Disease}|\text{Positive test})$ from known test accuracy

### Machine Learning
- Naive Bayes classifiers
- Bayesian inference and parameter estimation
- Updating model beliefs with new data

### Example: Medical Test

Given:
- Disease prevalence: $P(D) = 0.001$ (0.1%)
- Test sensitivity: $P(+|D) = 0.99$ (99%)
- Test specificity: $P(-|D^c) = 0.95$, so $P(+|D^c) = 0.05$

Find $P(D|+)$:
$$P(D|+) = \frac{0.99 \times 0.001}{0.99 \times 0.001 + 0.05 \times 0.999} = \frac{0.00099}{0.05094} \approx 0.0194$$

Despite a positive test, the probability of having the disease is only about 1.94%!

## Bayesian Updating

Bayes' theorem enables iterative belief updating:
1. Start with prior $P(A)$
2. Observe evidence $B$
3. Update to posterior $P(A|B)$
4. Use posterior as new prior for next observation

## Interactive Visualization

Explore the local knowledge graph neighborhood interactively:

::: {.graph-viz data-id="thm-bayes" data-width="700" data-height="500"}
:::

You can:
- **Drag** nodes to rearrange the layout
- **Zoom** in/out with your mouse wheel
- **Hover** over nodes to see details
- View the [full interactive version](../../output/interactive/en/thm-bayes.html){target="_blank"}
