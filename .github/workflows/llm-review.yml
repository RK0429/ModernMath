name: LLM Content Review

on:
  pull_request:
    types: [opened, synchronize]
    paths:
      - 'content/**/*.qmd'

jobs:
  review-content:
    runs-on: ubuntu-latest

    permissions:
      contents: read
      pull-requests: write

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install Poetry
        uses: snok/install-poetry@v1
        with:
          version: latest
          virtualenvs-create: true
          virtualenvs-in-project: true

      - name: Cache dependencies
        uses: actions/cache@v3
        with:
          path: .venv
          key: venv-${{ runner.os }}-poetry-${{ hashFiles('poetry.lock') }}

      - name: Install dependencies
        run: poetry install

      - name: Get changed files
        id: changed-files
        uses: tj-actions/changed-files@v41
        with:
          files: |
            content/**/*.qmd

      - name: Analyze content for missing links
        if: steps.changed-files.outputs.any_changed == 'true'
        id: analyze
        run: |
          # Create a Python script to analyze changed files
          cat > analyze_pr.py << 'EOF'
          import sys
          import json
          import os
          from pathlib import Path

          # Add project root to path
          sys.path.append(os.getcwd())
          from scripts.llm_integration import MathKnowledgeGraphLLM

          # Get changed files from environment
          changed_files = os.environ.get('CHANGED_FILES', '').split()

          # Read file contents
          file_contents = []
          for filepath in changed_files:
              if Path(filepath).exists():
                  with open(filepath, 'r', encoding='utf-8') as f:
                      content = f.read()
                      file_contents.append((filepath, content))

          # Analyze with LLM
          llm = MathKnowledgeGraphLLM()
          result = llm.analyze_pull_request(file_contents)

          # Save results
          with open('llm_analysis.json', 'w') as f:
              json.dump(result, f, indent=2)

          # Print summary
          print(f"Analyzed {result['total_files']} files")
          print(f"Found suggestions for {result['files_with_suggestions']} files")
          print(f"Total suggestions: {len(result['suggestions'])}")
          EOF

          # Run analysis
          export CHANGED_FILES="${{ steps.changed-files.outputs.all_changed_files }}"
          poetry run python analyze_pr.py

      - name: Format review comment
        if: steps.changed-files.outputs.any_changed == 'true'
        id: format-comment
        run: |
          cat > format_comment.py << 'EOF'
          import json
          import os

          # Load analysis results
          with open('llm_analysis.json', 'r') as f:
              result = json.load(f)

          # Format comment
          comment = "## ðŸ¤– Mathematical Content Review\n\n"

          if not result['suggestions']:
              comment += "âœ… No missing cross-references detected in the changed files.\n"
          else:
              comment += "### ðŸ“ Suggested Cross-References\n\n"
              comment += "The following mathematical concepts appear to be mentioned but not linked:\n\n"

              # Group by file
              by_file = {}
              for suggestion in result['suggestions']:
                  file = suggestion['file']
                  if file not in by_file:
                      by_file[file] = []
                  by_file[file].append(suggestion)

              for file, suggestions in by_file.items():
                  comment += f"**`{file}`**\n"
                  for s in suggestions:
                      comment += f"- Consider linking to `@{s['target']}` "
                      comment += f"(confidence: {s['confidence']:.0%})\n"
                      if s['evidence']:
                          # Escape special characters for GitHub
                          evidence = s['evidence'].replace('\n', ' ').strip()
                          if len(evidence) > 100:
                              evidence = evidence[:100] + "..."
                          comment += f"  > Context: *{evidence}*\n"
                  comment += "\n"

          comment += "\n---\n"
          comment += "*This is an automated review. Please verify suggestions before applying them.*\n"

          # Save comment to file
          with open('review_comment.md', 'w') as f:
              f.write(comment)

          # Set output for GitHub Actions
          print(f"::set-output name=has_suggestions::{len(result['suggestions']) > 0}")
          EOF

          poetry run python format_comment.py

      - name: Post review comment
        if: steps.changed-files.outputs.any_changed == 'true' && steps.format-comment.outputs.has_suggestions == 'true'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const comment = fs.readFileSync('review_comment.md', 'utf8');

            // Check if we already commented
            const { data: comments } = await github.rest.issues.listComments({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number,
            });

            const botComment = comments.find(comment =>
              comment.user.type === 'Bot' &&
              comment.body.includes('ðŸ¤– Mathematical Content Review')
            );

            if (botComment) {
              // Update existing comment
              await github.rest.issues.updateComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                comment_id: botComment.id,
                body: comment
              });
            } else {
              // Create new comment
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: context.issue.number,
                body: comment
              });
            }
